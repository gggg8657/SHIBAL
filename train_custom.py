#!/usr/bin/env python3
"""
ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ STEAD í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ë¥¼ í™œìš©í•œ ì´ìƒ íƒì§€ ëª¨ë¸ í›ˆë ¨
config.json íŒŒì¼ì—ì„œ ì„¤ì •ì„ ì½ì–´ì˜µë‹ˆë‹¤.
ë©€í‹° GPU ì§€ì› (GPU 0, 1ë²ˆ ë³‘ë ¬ ì²˜ë¦¬)
ì—¬ëŸ¬ ì„¤ì • íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ í•™ìŠµ ê°€ëŠ¥
"""

import torch
import torch.nn.functional as F
from torch import nn
from torch.nn.parallel import DataParallel
from tqdm import tqdm
from sklearn.metrics import auc, roc_curve, precision_recall_curve
import os
import datetime
import random
import numpy as np
import json
import argparse
from torch.utils.data import DataLoader
from segment_dataset import SegmentDataset
from model import Model
from utils import save_best_record
from timm.scheduler.cosine_lr import CosineLRScheduler

def parse_args():
    """ì»¤ë§¨ë“œë¼ì¸ ì•„ê·œë¨¼íŠ¸ íŒŒì‹±"""
    parser = argparse.ArgumentParser(description='ì»¤ìŠ¤í…€ STEAD í›ˆë ¨')
    parser.add_argument('--config', default='config.json', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.json)')
    parser.add_argument('--gpu_ids', type=str, default=None, help='ì‚¬ìš©í•  GPU ID (ì˜ˆ: 0,1 ë˜ëŠ” 0)')
    parser.add_argument('--batch_size', type=int, default=None, help='ë°°ì¹˜ í¬ê¸° (config.json ì˜¤ë²„ë¼ì´ë“œ)')
    parser.add_argument('--lr', type=float, default=None, help='í•™ìŠµë¥  (config.json ì˜¤ë²„ë¼ì´ë“œ)')
    parser.add_argument('--max_epoch', type=int, default=None, help='ìµœëŒ€ ì—í¬í¬ (config.json ì˜¤ë²„ë¼ì´ë“œ)')
    return parser.parse_args()

def load_config(config_path='config.json'):
    """config.json íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        print(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")
        return config
    except FileNotFoundError:
        print(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        print("config.json íŒŒì¼ì„ ìƒì„±í•˜ê±°ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

def print_config(config):
    """ì„¤ì •ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("\n=== í›ˆë ¨ ì„¤ì • ===")
    print(f"í›ˆë ¨ ë°ì´í„°: {config['data']['train_list']}")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {config['data']['test_list']}")
    print(f"ëª¨ë¸ ê²½ë¡œ: {config['data']['model_path']}")
    print(f"ëª¨ë¸ ì•„í‚¤í…ì²˜: {config['training']['model_arch']}")
    print(f"ë°°ì¹˜ í¬ê¸°: {config['training']['batch_size']}")
    print(f"í•™ìŠµë¥ : {config['training']['lr']}")
    print(f"ìµœëŒ€ ì—í¬í¬: {config['training']['max_epoch']}")
    print(f"ì €ì¥ ë””ë ‰í† ë¦¬: {config['training']['save_dir']}")
    print("=" * 30)

def setup_gpu(config, gpu_ids_arg=None):
    """GPU ì„¤ì •ì„ í™•ì¸í•˜ê³  ì„¤ì •í•©ë‹ˆë‹¤."""
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"ğŸ® ì‚¬ìš© ê°€ëŠ¥í•œ GPU: {gpu_count}ê°œ")
        
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"  GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
        
        # ì»¤ë§¨ë“œë¼ì¸ ì•„ê·œë¨¼íŠ¸ ìš°ì„  ì ìš©
        if gpu_ids_arg:
            gpu_ids = [int(x.strip()) for x in gpu_ids_arg.split(',')]
            use_multi_gpu = len(gpu_ids) > 1
            print(f"ğŸ¯ ì»¤ë§¨ë“œë¼ì¸ GPU ì„¤ì •: {gpu_ids}")
        else:
            # config.jsonì—ì„œ GPU ì„¤ì • ì½ê¸°
            gpu_config = config.get('gpu', {})
            use_multi_gpu = gpu_config.get('use_multi_gpu', True)
            gpu_ids = gpu_config.get('gpu_ids', [0, 1])
            auto_detect = gpu_config.get('auto_detect', True)
            
            if auto_detect and gpu_count >= 2 and use_multi_gpu:
                gpu_ids = [0, 1]  # ìµœëŒ€ 2ê°œ GPU ì‚¬ìš©
            elif not use_multi_gpu:
                gpu_ids = [0]
        
        if len(gpu_ids) > 1:
            print(f"âœ… ë©€í‹° GPU ëª¨ë“œ í™œì„±í™” (GPU {gpu_ids} ë³‘ë ¬)")
            device = torch.device(f'cuda:{gpu_ids[0]}')
            return device, True, len(gpu_ids), gpu_ids
        else:
            print("âš ï¸ ë‹¨ì¼ GPU ëª¨ë“œ (GPU 0ë²ˆë§Œ ì‚¬ìš©)")
            device = torch.device('cuda:0')
            return device, False, 1, [0]
    else:
        print("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        return torch.device('cpu'), False, 0, []

class TripletLoss(nn.Module):
    def __init__(self):
        super(TripletLoss, self).__init__()

    def distance(self, x, y):
        d = torch.cdist(x, y, p=2)
        return d

    def forward(self, feats, margin = 100.0):
        bs = len(feats)
        n_feats = feats[:bs // 2]
        a_feats = feats[bs // 2:]
        n_d = self.distance(n_feats, n_feats)
        a_d = self.distance(n_feats, a_feats)
        n_d_max, _ = torch.max(n_d, dim=0)
        a_d_min, _ = torch.min(a_d, dim=0)
        a_d_min = margin - a_d_min
        a_d_min = torch.max(torch.zeros(bs // 2).cuda(), a_d_min)
        return torch.mean(n_d_max) + torch.mean(a_d_min)

class Loss(torch.nn.Module):
    def __init__(self):
        super(Loss, self).__init__()
        self.criterion = torch.nn.BCEWithLogitsLoss()
        self.triplet = TripletLoss()

    def forward(self, scores, feats, targets, alpha = 0.01):
        loss_ce = self.criterion(scores, targets)
        loss_triplet = self.triplet(feats)
        return loss_ce, alpha * loss_triplet

def train(loader, model, optimizer, scheduler, device, epoch, use_multi_gpu=False):
    """í›ˆë ¨ í•¨ìˆ˜"""
    with torch.set_grad_enabled(True):
        model.train()
        pred = []
        label = []
        for step, (ninput, nlabel, ainput, alabel, ncategory, acategory) in tqdm(enumerate(loader), desc=f"Epoch {epoch}"):
            input = torch.cat((ninput, ainput), 0).to(device)
            
            scores, feats = model(input) 
            pred += scores.cpu().detach().tolist()
            labels = torch.cat((nlabel, alabel), 0).to(device)
            label += labels.cpu().detach().tolist()

            loss_criterion = Loss()
            loss_ce, loss_con = loss_criterion(scores.squeeze(), feats, labels)
            loss = loss_ce + loss_con

            optimizer.zero_grad()
            loss.backward()

            optimizer.step()
            scheduler.step_update(epoch * len(loader) + step)
        
        fpr, tpr, _ = roc_curve(label, pred)
        roc_auc = auc(fpr, tpr)
        precision, recall, _ = precision_recall_curve(label, pred)
        pr_auc = auc(recall, precision)
        print(f'train_pr_auc : {pr_auc:.4f}')
        print(f'train_roc_auc : {roc_auc:.4f}')
        return loss.item()

def test(dataloader, model, config, device, use_multi_gpu=False):
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    model.to(device)
    with torch.no_grad():
        model.eval()
        pred = []
        labels = []
        for _, inputs in tqdm(enumerate(dataloader), desc="í…ŒìŠ¤íŠ¸"):
            if len(inputs) == 4:  # features, label, category, description
                features, label, category, description = inputs
            else:
                features, label = inputs
            
            labels += label.cpu().detach().tolist()
            input = features.to(device)
            
            scores, _ = model(input)
            pred += scores.cpu().detach().tolist()
        
        fpr, tpr, _ = roc_curve(labels, pred)
        roc_auc = auc(fpr, tpr)
        precision, recall, _ = precision_recall_curve(labels, pred)
        pr_auc = auc(recall, precision)
        print(f'pr_auc : {pr_auc:.4f}')
        print(f'roc_auc : {roc_auc:.4f}')
        return roc_auc, pr_auc

def init_weights(m):
    """ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
    if isinstance(m, nn.Linear):
        torch.nn.init.xavier_uniform_(m.weight)
        if m.bias is not None:
            torch.nn.init.zeros_(m.bias)
    elif isinstance(m, nn.Conv1d):
         torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
    elif isinstance(m, nn.Conv2d):
         torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')     
    elif isinstance(m, nn.Conv3d):
        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')

def save_config(save_path, args):
    """ì„¤ì • ì €ì¥"""
    path = save_path+'/'
    os.makedirs(path, exist_ok=True)
    f = open(path + "config_{}.txt".format(datetime.datetime.now()), 'w')
    for key in vars(args).keys():
        f.write('{}: {}'.format(key, vars(args)[key]))
        f.write('\n')
    f.close()

def main():
    # ì»¤ë§¨ë“œë¼ì¸ ì•„ê·œë¨¼íŠ¸ íŒŒì‹±
    args = parse_args()
    
    # ì„¤ì • íŒŒì¼ ë¡œë“œ
    config = load_config(args.config)
    if config is None:
        return
    
    # ì»¤ë§¨ë“œë¼ì¸ ì•„ê·œë¨¼íŠ¸ë¡œ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    if args.batch_size is not None:
        config['training']['batch_size'] = args.batch_size
        print(f"ğŸ¯ ë°°ì¹˜ í¬ê¸° ì˜¤ë²„ë¼ì´ë“œ: {args.batch_size}")
    
    if args.lr is not None:
        config['training']['lr'] = args.lr
        print(f"ğŸ¯ í•™ìŠµë¥  ì˜¤ë²„ë¼ì´ë“œ: {args.lr}")
    
    if args.max_epoch is not None:
        config['training']['max_epoch'] = args.max_epoch
        print(f"ğŸ¯ ìµœëŒ€ ì—í¬í¬ ì˜¤ë²„ë¼ì´ë“œ: {args.max_epoch}")
    
    print_config(config)
    
    # GPU ì„¤ì •
    device, use_multi_gpu, gpu_count, gpu_ids = setup_gpu(config, args.gpu_ids)
    
    # ë°ì´í„° ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    train_list = config['data']['train_list']
    test_list = config['data']['test_list']
    
    if not os.path.exists(train_list):
        print(f"âŒ í›ˆë ¨ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_list}")
        print("ë¨¼ì € preprocess_segments.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”.")
        return
    
    if not os.path.exists(test_list):
        print(f"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_list}")
        print("ë¨¼ì € preprocess_segments.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”.")
        return
    
    # ì‹œë“œ ì„¤ì •
    random.seed(2025)
    np.random.seed(2025)
    torch.cuda.manual_seed(2025)
    
    # ë°ì´í„° ë¡œë” ìƒì„±
    try:
        # SegmentDatasetì— í•„ìš”í•œ args ê°ì²´ ìƒì„±
        class Args:
            def __init__(self, config):
                self.rgb_list = config['data']['train_list']
                self.test_rgb_list = config['data']['test_list']
                self.batch_size = config['training']['batch_size']
        
        args_obj = Args(config)
        
        # ë©€í‹° GPU ì‚¬ìš© ì‹œ ë°°ì¹˜ í¬ê¸° ì¡°ì •
        if use_multi_gpu:
            effective_batch_size = config['training']['batch_size'] // gpu_count
            print(f"ğŸ¯ GPU {gpu_count}ê°œ ì‚¬ìš©ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸° ì¡°ì •: {config['training']['batch_size']} â†’ {effective_batch_size} (GPUë‹¹)")
        else:
            effective_batch_size = config['training']['batch_size']
        
        train_loader = DataLoader(SegmentDataset(args_obj, test_mode=False),
                                   batch_size=effective_batch_size // 2)
        test_loader = DataLoader(SegmentDataset(args_obj, test_mode=True),
                                 batch_size=effective_batch_size)
        
        print(f"í›ˆë ¨ ë°ì´í„°: {len(train_loader.dataset)}ê°œ")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_loader.dataset)}ê°œ")
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë” ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # ëª¨ë¸ ìƒì„±
    model_config = config['model']
    if config['training']['model_arch'] == 'base':
        model = Model(dropout=config['training']['dropout_rate'], 
                     attn_dropout=config['training']['attn_dropout_rate'])
    elif config['training']['model_arch'] == 'fast' or config['training']['model_arch'] == 'tiny':
        model = Model(dropout=config['training']['dropout_rate'], 
                     attn_dropout=config['training']['attn_dropout_rate'], 
                     ff_mult=model_config['ff_mult'], 
                     dims=tuple(model_config['dims']), 
                     depths=tuple(model_config['depths']))
    else:
        print("âŒ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return
    
    model.apply(init_weights)
    
    # í”„ë¦¬íŠ¸ë ˆì¸ë“œ ëª¨ë¸ ë¡œë“œ
    model_path = config['data']['model_path']
    if model_path and model_path != "null" and os.path.exists(model_path):
        try:
            model_ckpt = torch.load(model_path, map_location=device)
            model.load_state_dict(model_ckpt, strict=False)
            print(f"âœ… í”„ë¦¬íŠ¸ë ˆì¸ë“œ ëª¨ë¸ ë¡œë“œ: {model_path}")
        except Exception as e:
            print(f"âŒ í”„ë¦¬íŠ¸ë ˆì¸ë“œ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
    else:
        print(f"ğŸ¯ From Scratch í•™ìŠµ ëª¨ë“œ")
        print("ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
    
    # ë©€í‹° GPU ì„¤ì •
    if use_multi_gpu:
        model = DataParallel(model, device_ids=gpu_ids)
        print(f"âœ… DataParallel í™œì„±í™” (GPU {gpu_ids} ë³‘ë ¬)")
    
    model = model.to(device)
    
    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± (ì„¤ì • íŒŒì¼ëª… í¬í•¨)
    config_name = os.path.splitext(os.path.basename(args.config))[0]
    savepath = os.path.join(config['training']['save_dir'], 
                           f"{config_name}_{config['training']['lr']}_{config['training']['batch_size']}_{config['training']['comment']}")
    os.makedirs(savepath, exist_ok=True)
    
    # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    optimizer = torch.optim.AdamW(model.parameters(), lr=config['training']['lr'], weight_decay=0.2)
    
    num_steps = len(train_loader)
    scheduler = CosineLRScheduler(
            optimizer,
            t_initial=config['training']['max_epoch'] * num_steps,
            cycle_mul=1.,
            lr_min=config['training']['lr'] * 0.2,
            warmup_lr_init=config['training']['lr'] * 0.01,
            warmup_t=config['training']['warmup'] * num_steps,
            cycle_limit=20,
            t_in_epochs=False,
            warmup_prefix=True,
            cycle_decay=0.95,
        )
    
    # í›ˆë ¨ ë£¨í”„
    test_info = {"epoch": [], "test_AUC": [], "test_PR":[]}
    
    print("\n=== í›ˆë ¨ ì‹œì‘ ===")
    for step in tqdm(range(0, config['training']['max_epoch']), 
                     total=config['training']['max_epoch'], desc="ì „ì²´ ì§„í–‰ë¥ "):
        cost = train(train_loader, model, optimizer, scheduler, device, step, use_multi_gpu)
        scheduler.step(step + 1)
        
        # í…ŒìŠ¤íŠ¸
        auc, pr_auc = test(test_loader, model, config, device, use_multi_gpu)
        
        test_info["epoch"].append(step)
        test_info["test_AUC"].append(auc)
        test_info["test_PR"].append(pr_auc)
        
        # ëª¨ë¸ ì €ì¥ (DataParallel ì‚¬ìš© ì‹œ module ì ‘ê·¼)
        if use_multi_gpu:
            model_state_dict = model.module.state_dict()
        else:
            model_state_dict = model.state_dict()
            
        torch.save(model_state_dict, 
                  f'{savepath}/{config["training"]["model_name"]}{step}-x3d.pkl')
        save_best_record(test_info, os.path.join(savepath, f'{step}-step.txt'))
        
        print(f"Epoch {step}: AUC={auc:.4f}, PR_AUC={pr_auc:.4f}")
    
    # ìµœì¢… ëª¨ë¸ ì €ì¥
    if use_multi_gpu:
        model_state_dict = model.module.state_dict()
    else:
        model_state_dict = model.state_dict()
        
    torch.save(model_state_dict, 
              f'{savepath}/{config["training"]["model_name"]}final.pkl')
    print(f"\nâœ… í›ˆë ¨ ì™„ë£Œ! ëª¨ë¸ì´ {savepath}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
