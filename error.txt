=== End-to-End 훈련 시작 ===
Epoch 0:   0%|                                                                                                                      | 0/2081 [00:01<?, ?it/s]
전체 진행률:   0%|                                                                                                                    | 0/50 [00:01<?, ?it/s] 
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom_e2e.py", line 676, in <module>
    main()
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom_e2e.py", line 603, in main
    train_loss = train(train_loader, model, optimizer, scheduler, device, epoch, use_multi_gpu)
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom_e2e.py", line 396, in train
    total_loss_step.backward()
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\autograd\__init__.py", line 353, in backward
    _engine_run_backward(
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\autograd\graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn