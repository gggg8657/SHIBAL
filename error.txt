Simple preprocess 입력: torch.Size([1, 16, 3, 480, 640])
Simple preprocess 출력: torch.Size([1, 16, 3, 320, 320])
Simple preprocess 후 형태: torch.Size([1, 16, 3, 320, 320])
특징 추출 실패: D:\output_2025\frame_20250728-143012_840.jpg, 에러: Given groups=1, weight of size [24, 3, 1, 3, 3], expected input[1, 16, 3, 320, 320] to have 3 channels, but got 16 channels instead
입력 텐서 형태: torch.Size([1, 16, 3, 480, 640])
경고: 입력 텐서 차원 5과 permute 차원 4이 일치하지 않습니다.
입력 텐서 형태: torch.Size([1, 16, 16, 480, 640])
Transform 적용 실패: The size of tensor a (16) must match the size of tensor b (3) at non-singleton dimension 1
Simple preprocess 입력: torch.Size([1, 16, 3, 480, 640])
Simple preprocess 출력: torch.Size([1, 16, 3, 320, 320])
Simple preprocess 후 형태: torch.Size([1, 16, 3, 320, 320])
특징 추출 실패: D:\output_2025\frame_20250728-143012_873.jpg, 에러: Given groups=1, weight of size [24, 3, 1, 3, 3], expected input[1, 16, 3, 320, 320] to have 3 channels, but got 16 channels instead
입력 텐서 형태: torch.Size([1, 16, 3, 480, 640])
경고: 입력 텐서 차원 5과 permute 차원 4이 일치하지 않습니다.
입력 텐서 형태: torch.Size([1, 16, 16, 480, 640])
Transform 적용 실패: The size of tensor a (16) must match the size of tensor b (3) at non-singleton dimension 1
Simple preprocess 입력: torch.Size([1, 16, 3, 480, 640])
Simple preprocess 출력: torch.Size([1, 16, 3, 320, 320])
Simple preprocess 후 형태: torch.Size([1, 16, 3, 320, 320])
특징 추출 실패: D:\output_2025\frame_20250728-143012_906.jpg, 에러: Given groups=1, weight of size [24, 3, 1, 3, 3], expected input[1, 16, 3, 320, 320] to have 3 channels, but got 16 channels instead
입력 텐서 형태: torch.Size([1, 16, 3, 480, 640])
경고: 입력 텐서 차원 5과 permute 차원 4이 일치하지 않습니다.
입력 텐서 형태: torch.Size([1, 16, 16, 480, 640])
Transform 적용 실패: The size of tensor a (16) must match the size of tensor b (3) at non-singleton dimension 1
Simple preprocess 입력: torch.Size([1, 16, 3, 480, 640])


입력 텐서 형태: torch.Size([1, 16, 3, 480, 640])
Transform 적용 실패: The size of tensor a (16) must match the size of tensor b (3) at non-singleton dimension 1
Simple preprocess 입력: torch.Size([1, 16, 3, 480, 640])
Simple preprocess 출력: torch.Size([1, 16, 3, 320, 320])
Simple preprocess 후 형태: torch.Size([1, 16, 3, 320, 320])
모델 입력용 변환 후: torch.Size([1, 3, 16, 320, 320])

913base 오류
(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL> python test_custom.py
모델 로드 중: ./saved_models/913base.pkl
❌ 테스트 실행 중 오류 발생: Error(s) in loading state_dict for Model:
        Missing key(s) in state_dict: "stages.1.0.weight", "stages.1.0.bias", "stages.1.1.weight", "stages.1.1.bias", "stages.2.performer.net.layers.0.0.norm.weight", "stages.2.performer.net.layers.0.0.norm.bias", "stages.2.perf
ormer.net.layers.0.0.fn.fast_attention.projection_matrix", "stages.2.performer.net.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.2.performer.net.layers.0.0.fn.to_q.weight", "stages.2.performer.net.layers.0.0.fn.to_q.bias",
 "stages.2.performer.net.layers.0.0.fn.to_k.weight", "stages.2.performer.net.layers.0.0.fn.to_k.bias", "stages.2.performer.net.layers.0.0.fn.to_v.weight", "stages.2.performer.net.layers.0.0.fn.to_v.bias", "stages.2.performer.net
.layers.0.0.fn.to_out.weight", "stages.2.performer.net.layers.0.0.fn.to_out.bias", "stages.2.performer.net.layers.0.1.norm.weight", "stages.2.performer.net.layers.0.1.norm.bias", "stages.2.performer.net.layers.0.1.fn.fn.w1.weigh
t", "stages.2.performer.net.layers.0.1.fn.fn.w1.bias", "stages.2.performer.net.layers.0.1.fn.fn.w2.weight", "stages.2.performer.net.layers.0.1.fn.fn.w2.bias", "stages.2.performer.proj_updater.calls_since_last_redraw", "stages.2.
performer.proj_updater.instance.layers.0.0.norm.weight", "stages.2.performer.proj_updater.instance.layers.0.0.norm.bias", "stages.2.performer.proj_updater.instance.layers.0.0.fn.fast_attention.projection_matrix", "stages.2.perfo
rmer.proj_updater.instance.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_q.weight", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_q.bias", "stages.2.performer
.proj_updater.instance.layers.0.0.fn.to_k.weight", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_k.bias", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_v.weight", "stages.2.performer.proj_updater.instan
ce.layers.0.0.fn.to_v.bias", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_out.weight", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_out.bias", "stages.2.performer.proj_updater.instance.layers.0.1.norm
.weight", "stages.2.performer.proj_updater.instance.layers.0.1.norm.bias", "stages.2.performer.proj_updater.instance.layers.0.1.fn.fn.w1.weight", "stages.2.performer.proj_updater.instance.layers.0.1.fn.fn.w1.bias", "stages.2.performer.proj_updater.instance.layers.0.1.fn.fn.w2.weight", "stages.2.performer.proj_updater.instance.layers.0.1.fn.fn.w2.bias".
        Unexpected key(s) in state_dict: "stages.3.0.weight", "stages.3.0.bias", "stages.3.1.weight", "stages.3.1.bias", "stages.4.performer.net.layers.0.0.norm.weight", "stages.4.performer.net.layers.0.0.norm.bias", "stages.4.p
erformer.net.layers.0.0.fn.fast_attention.projection_matrix", "stages.4.performer.net.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.4.performer.net.layers.0.0.fn.to_q.weight", "stages.4.performer.net.layers.0.0.fn.to_q.bia
s", "stages.4.performer.net.layers.0.0.fn.to_k.weight", "stages.4.performer.net.layers.0.0.fn.to_k.bias", "stages.4.performer.net.layers.0.0.fn.to_v.weight", "stages.4.performer.net.layers.0.0.fn.to_v.bias", "stages.4.performer.
net.layers.0.0.fn.to_out.weight", "stages.4.performer.net.layers.0.0.fn.to_out.bias", "stages.4.performer.net.layers.0.1.norm.weight", "stages.4.performer.net.layers.0.1.norm.bias", "stages.4.performer.net.layers.0.1.fn.fn.w1.we
ight", "stages.4.performer.net.layers.0.1.fn.fn.w1.bias", "stages.4.performer.net.layers.0.1.fn.fn.w2.weight", "stages.4.performer.net.layers.0.1.fn.fn.w2.bias", "stages.4.performer.proj_updater.calls_since_last_redraw", "stages
.4.performer.proj_updater.instance.layers.0.0.norm.weight", "stages.4.performer.proj_updater.instance.layers.0.0.norm.bias", "stages.4.performer.proj_updater.instance.layers.0.0.fn.fast_attention.projection_matrix", "stages.4.pe
rformer.proj_updater.instance.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_q.weight", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_q.bias", "stages.4.perfor
mer.proj_updater.instance.layers.0.0.fn.to_k.weight", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_k.bias", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_v.weight", "stages.4.performer.proj_updater.ins
tance.layers.0.0.fn.to_v.bias", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_out.weight", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_out.bias", "stages.4.performer.proj_updater.instance.layers.0.1.n
orm.weight", "stages.4.performer.proj_updater.instance.layers.0.1.norm.bias", "stages.4.performer.proj_updater.instance.layers.0.1.fn.fn.w1.weight", "stages.4.performer.proj_updater.instance.layers.0.1.fn.fn.w1.bias", "stages.4.
performer.proj_updater.instance.layers.0.1.fn.fn.w2.weight", "stages.4.performer.proj_updater.instance.layers.0.1.fn.fn.w2.bias", "stages.5.performer.net.layers.0.0.norm.weight", "stages.5.performer.net.layers.0.0.norm.bias", "s
tages.5.performer.net.layers.0.0.fn.fast_attention.projection_matrix", "stages.5.performer.net.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.5.performer.net.layers.0.0.fn.to_q.weight", "stages.5.performer.net.layers.0.0.fn
.to_q.bias", "stages.5.performer.net.layers.0.0.fn.to_k.weight", "stages.5.performer.net.layers.0.0.fn.to_k.bias", "stages.5.performer.net.layers.0.0.fn.to_v.weight", "stages.5.performer.net.layers.0.0.fn.to_v.bias", "stages.5.p
erformer.net.layers.0.0.fn.to_out.weight", "stages.5.performer.net.layers.0.0.fn.to_out.bias", "stages.5.performer.net.layers.0.1.norm.weight", "stages.5.performer.net.layers.0.1.norm.bias", "stages.5.performer.net.layers.0.1.fn
.fn.w1.weight", "stages.5.performer.net.layers.0.1.fn.fn.w1.bias", "stages.5.performer.net.layers.0.1.fn.fn.w2.weight", "stages.5.performer.net.layers.0.1.fn.fn.w2.bias", "stages.5.performer.proj_updater.calls_since_last_redraw"
, "stages.5.performer.proj_updater.instance.layers.0.0.norm.weight", "stages.5.performer.proj_updater.instance.layers.0.0.norm.bias", "stages.5.performer.proj_updater.instance.layers.0.0.fn.fast_attention.projection_matrix", "st
ages.5.performer.proj_updater.instance.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_q.weight", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_q.bias", "stages
.5.performer.proj_updater.instance.layers.0.0.fn.to_k.weight", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_k.bias", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_v.weight", "stages.5.performer.proj_up
dater.instance.layers.0.0.fn.to_v.bias", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_out.weight", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_out.bias", "stages.5.performer.proj_updater.instance.lay
ers.0.1.norm.weight", "stages.5.performer.proj_updater.instance.layers.0.1.norm.bias", "stages.5.performer.proj_updater.instance.layers.0.1.fn.fn.w1.weight", "stages.5.performer.proj_updater.instance.layers.0.1.fn.fn.w1.bias", "
stages.5.performer.proj_updater.instance.layers.0.1.fn.fn.w2.weight", "stages.5.performer.proj_updater.instance.layers.0.1.fn.fn.w2.bias", "stages.6.performer.net.layers.0.0.norm.weight", "stages.6.performer.net.layers.0.0.norm.
bias", "stages.6.performer.net.layers.0.0.fn.fast_attention.projection_matrix", "stages.6.performer.net.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.6.performer.net.layers.0.0.fn.to_q.weight", "stages.6.performer.net.laye
rs.0.0.fn.to_q.bias", "stages.6.performer.net.layers.0.0.fn.to_k.weight", "stages.6.performer.net.layers.0.0.fn.to_k.bias", "stages.6.performer.net.layers.0.0.fn.to_v.weight", "stages.6.performer.net.layers.0.0.fn.to_v.bias", "s
tages.6.performer.net.layers.0.0.fn.to_out.weight", "stages.6.performer.net.layers.0.0.fn.to_out.bias", "stages.6.performer.net.layers.0.1.norm.weight", "stages.6.performer.net.layers.0.1.norm.bias", "stages.6.performer.net.laye
rs.0.1.fn.fn.w1.weight", "stages.6.performer.net.layers.0.1.fn.fn.w1.bias", "stages.6.performer.net.layers.0.1.fn.fn.w2.weight", "stages.6.performer.net.layers.0.1.fn.fn.w2.bias", "stages.6.performer.proj_updater.calls_since_las
t_redraw", "stages.6.performer.proj_updater.instance.layers.0.0.norm.weight", "stages.6.performer.proj_updater.instance.layers.0.0.norm.bias", "stages.6.performer.proj_updater.instance.layers.0.0.fn.fast_attention.projection_mat
rix", "stages.6.performer.proj_updater.instance.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_q.weight", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_q.bias"
, "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_k.weight", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_k.bias", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_v.weight", "stages.6.performe
r.proj_updater.instance.layers.0.0.fn.to_v.bias", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_out.weight", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_out.bias", "stages.6.performer.proj_updater.ins
tance.layers.0.1.norm.weight", "stages.6.performer.proj_updater.instance.layers.0.1.norm.bias", "stages.6.performer.proj_updater.instance.layers.0.1.fn.fn.w1.weight", "stages.6.performer.proj_updater.instance.layers.0.1.fn.fn.w1
.bias", "stages.6.performer.proj_updater.instance.layers.0.1.fn.fn.w2.weight", "stages.6.performer.proj_updater.instance.layers.0.1.fn.fn.w2.bias", "stages.1.norm1.weight", "stages.1.norm1.bias", "stages.1.norm2.weight", "stages
.1.norm2.bias", "stages.1.conv.norm2d.weight", "stages.1.conv.norm2d.bias", "stages.1.conv.norm2d.running_mean", "stages.1.conv.norm2d.running_var", "stages.1.conv.norm2d.num_batches_tracked", "stages.1.conv.norm1d.weight", "sta
ges.1.conv.norm1d.bias", "stages.1.conv.norm1d.running_mean", "stages.1.conv.norm1d.running_var", "stages.1.conv.norm1d.num_batches_tracked", "stages.1.conv.conv2d.weight", "stages.1.conv.conv2d.bias", "stages.1.conv.conv1d.weig
ht", "stages.1.conv.conv1d.bias", "stages.1.ff.0.weight", "stages.1.ff.0.bias", "stages.1.ff.3.weight", "stages.1.ff.3.bias", "stages.2.norm1.weight", "stages.2.norm1.bias", "stages.2.norm2.weight", "stages.2.norm2.bias", "stage
s.2.conv.norm2d.weight", "stages.2.conv.norm2d.bias", "stages.2.conv.norm2d.running_mean", "stages.2.conv.norm2d.running_var", "stages.2.conv.norm2d.num_batches_tracked", "stages.2.conv.norm1d.weight", "stages.2.conv.norm1d.bias
", "stages.2.conv.norm1d.running_mean", "stages.2.conv.norm1d.running_var", "stages.2.conv.norm1d.num_batches_tracked", "stages.2.conv.conv2d.weight", "stages.2.conv.conv2d.bias", "stages.2.conv.conv1d.weight", "stages.2.conv.conv1d.bias", "stages.2.ff.0.weight", "stages.2.ff.0.bias", "stages.2.ff.3.weight", "stages.2.ff.3.bias".
        size mismatch for stages.0.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm2d.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm2d.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm2d.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm2d.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm1d.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm1d.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm1d.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm1d.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.conv2d.weight: copying a param with shape torch.Size([192, 12, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 2, 3, 3]).
        size mismatch for stages.0.conv.conv2d.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.conv1d.weight: copying a param with shape torch.Size([192, 12, 3]) from checkpoint, the shape in current model is torch.Size([32, 2, 3]).
        size mismatch for stages.0.conv.conv1d.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.ff.0.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([32, 32]).
        size mismatch for stages.0.ff.0.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.ff.3.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([32, 32]).
        size mismatch for stages.0.ff.3.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([32, 192]).
        size mismatch for linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for fc.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([1, 32]).
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 325, in main
    tester = CustomTester(args.model_path, stead_args)
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 24, in __init__
    self.model = self.load_model(model_path)
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 37, in load_model
    model.load_state_dict(torch.load(model_path, map_location=self.device))
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 2593, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for Model:
        Missing key(s) in state_dict: "stages.1.0.weight", "stages.1.0.bias", "stages.1.1.weight", "stages.1.1.bias", "stages.2.performer.net.layers.0.0.norm.weight", "stages.2.performer.net.layers.0.0.norm.bias", "stages.2.perf
ormer.net.layers.0.0.fn.fast_attention.projection_matrix", "stages.2.performer.net.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.2.performer.net.layers.0.0.fn.to_q.weight", "stages.2.performer.net.layers.0.0.fn.to_q.bias",
 "stages.2.performer.net.layers.0.0.fn.to_k.weight", "stages.2.performer.net.layers.0.0.fn.to_k.bias", "stages.2.performer.net.layers.0.0.fn.to_v.weight", "stages.2.performer.net.layers.0.0.fn.to_v.bias", "stages.2.performer.net
.layers.0.0.fn.to_out.weight", "stages.2.performer.net.layers.0.0.fn.to_out.bias", "stages.2.performer.net.layers.0.1.norm.weight", "stages.2.performer.net.layers.0.1.norm.bias", "stages.2.performer.net.layers.0.1.fn.fn.w1.weigh
t", "stages.2.performer.net.layers.0.1.fn.fn.w1.bias", "stages.2.performer.net.layers.0.1.fn.fn.w2.weight", "stages.2.performer.net.layers.0.1.fn.fn.w2.bias", "stages.2.performer.proj_updater.calls_since_last_redraw", "stages.2.
performer.proj_updater.instance.layers.0.0.norm.weight", "stages.2.performer.proj_updater.instance.layers.0.0.norm.bias", "stages.2.performer.proj_updater.instance.layers.0.0.fn.fast_attention.projection_matrix", "stages.2.perfo
rmer.proj_updater.instance.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_q.weight", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_q.bias", "stages.2.performer
.proj_updater.instance.layers.0.0.fn.to_k.weight", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_k.bias", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_v.weight", "stages.2.performer.proj_updater.instan
ce.layers.0.0.fn.to_v.bias", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_out.weight", "stages.2.performer.proj_updater.instance.layers.0.0.fn.to_out.bias", "stages.2.performer.proj_updater.instance.layers.0.1.norm
.weight", "stages.2.performer.proj_updater.instance.layers.0.1.norm.bias", "stages.2.performer.proj_updater.instance.layers.0.1.fn.fn.w1.weight", "stages.2.performer.proj_updater.instance.layers.0.1.fn.fn.w1.bias", "stages.2.performer.proj_updater.instance.layers.0.1.fn.fn.w2.weight", "stages.2.performer.proj_updater.instance.layers.0.1.fn.fn.w2.bias".
        Unexpected key(s) in state_dict: "stages.3.0.weight", "stages.3.0.bias", "stages.3.1.weight", "stages.3.1.bias", "stages.4.performer.net.layers.0.0.norm.weight", "stages.4.performer.net.layers.0.0.norm.bias", "stages.4.p
erformer.net.layers.0.0.fn.fast_attention.projection_matrix", "stages.4.performer.net.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.4.performer.net.layers.0.0.fn.to_q.weight", "stages.4.performer.net.layers.0.0.fn.to_q.bia
s", "stages.4.performer.net.layers.0.0.fn.to_k.weight", "stages.4.performer.net.layers.0.0.fn.to_k.bias", "stages.4.performer.net.layers.0.0.fn.to_v.weight", "stages.4.performer.net.layers.0.0.fn.to_v.bias", "stages.4.performer.
net.layers.0.0.fn.to_out.weight", "stages.4.performer.net.layers.0.0.fn.to_out.bias", "stages.4.performer.net.layers.0.1.norm.weight", "stages.4.performer.net.layers.0.1.norm.bias", "stages.4.performer.net.layers.0.1.fn.fn.w1.we
ight", "stages.4.performer.net.layers.0.1.fn.fn.w1.bias", "stages.4.performer.net.layers.0.1.fn.fn.w2.weight", "stages.4.performer.net.layers.0.1.fn.fn.w2.bias", "stages.4.performer.proj_updater.calls_since_last_redraw", "stages
.4.performer.proj_updater.instance.layers.0.0.norm.weight", "stages.4.performer.proj_updater.instance.layers.0.0.norm.bias", "stages.4.performer.proj_updater.instance.layers.0.0.fn.fast_attention.projection_matrix", "stages.4.pe
rformer.proj_updater.instance.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_q.weight", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_q.bias", "stages.4.perfor
mer.proj_updater.instance.layers.0.0.fn.to_k.weight", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_k.bias", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_v.weight", "stages.4.performer.proj_updater.ins
tance.layers.0.0.fn.to_v.bias", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_out.weight", "stages.4.performer.proj_updater.instance.layers.0.0.fn.to_out.bias", "stages.4.performer.proj_updater.instance.layers.0.1.n
orm.weight", "stages.4.performer.proj_updater.instance.layers.0.1.norm.bias", "stages.4.performer.proj_updater.instance.layers.0.1.fn.fn.w1.weight", "stages.4.performer.proj_updater.instance.layers.0.1.fn.fn.w1.bias", "stages.4.
performer.proj_updater.instance.layers.0.1.fn.fn.w2.weight", "stages.4.performer.proj_updater.instance.layers.0.1.fn.fn.w2.bias", "stages.5.performer.net.layers.0.0.norm.weight", "stages.5.performer.net.layers.0.0.norm.bias", "s
tages.5.performer.net.layers.0.0.fn.fast_attention.projection_matrix", "stages.5.performer.net.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.5.performer.net.layers.0.0.fn.to_q.weight", "stages.5.performer.net.layers.0.0.fn
.to_q.bias", "stages.5.performer.net.layers.0.0.fn.to_k.weight", "stages.5.performer.net.layers.0.0.fn.to_k.bias", "stages.5.performer.net.layers.0.0.fn.to_v.weight", "stages.5.performer.net.layers.0.0.fn.to_v.bias", "stages.5.p
erformer.net.layers.0.0.fn.to_out.weight", "stages.5.performer.net.layers.0.0.fn.to_out.bias", "stages.5.performer.net.layers.0.1.norm.weight", "stages.5.performer.net.layers.0.1.norm.bias", "stages.5.performer.net.layers.0.1.fn
.fn.w1.weight", "stages.5.performer.net.layers.0.1.fn.fn.w1.bias", "stages.5.performer.net.layers.0.1.fn.fn.w2.weight", "stages.5.performer.net.layers.0.1.fn.fn.w2.bias", "stages.5.performer.proj_updater.calls_since_last_redraw"
, "stages.5.performer.proj_updater.instance.layers.0.0.norm.weight", "stages.5.performer.proj_updater.instance.layers.0.0.norm.bias", "stages.5.performer.proj_updater.instance.layers.0.0.fn.fast_attention.projection_matrix", "st
ages.5.performer.proj_updater.instance.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_q.weight", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_q.bias", "stages
.5.performer.proj_updater.instance.layers.0.0.fn.to_k.weight", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_k.bias", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_v.weight", "stages.5.performer.proj_up
dater.instance.layers.0.0.fn.to_v.bias", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_out.weight", "stages.5.performer.proj_updater.instance.layers.0.0.fn.to_out.bias", "stages.5.performer.proj_updater.instance.lay
ers.0.1.norm.weight", "stages.5.performer.proj_updater.instance.layers.0.1.norm.bias", "stages.5.performer.proj_updater.instance.layers.0.1.fn.fn.w1.weight", "stages.5.performer.proj_updater.instance.layers.0.1.fn.fn.w1.bias", "
stages.5.performer.proj_updater.instance.layers.0.1.fn.fn.w2.weight", "stages.5.performer.proj_updater.instance.layers.0.1.fn.fn.w2.bias", "stages.6.performer.net.layers.0.0.norm.weight", "stages.6.performer.net.layers.0.0.norm.
bias", "stages.6.performer.net.layers.0.0.fn.fast_attention.projection_matrix", "stages.6.performer.net.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.6.performer.net.layers.0.0.fn.to_q.weight", "stages.6.performer.net.laye
rs.0.0.fn.to_q.bias", "stages.6.performer.net.layers.0.0.fn.to_k.weight", "stages.6.performer.net.layers.0.0.fn.to_k.bias", "stages.6.performer.net.layers.0.0.fn.to_v.weight", "stages.6.performer.net.layers.0.0.fn.to_v.bias", "s
tages.6.performer.net.layers.0.0.fn.to_out.weight", "stages.6.performer.net.layers.0.0.fn.to_out.bias", "stages.6.performer.net.layers.0.1.norm.weight", "stages.6.performer.net.layers.0.1.norm.bias", "stages.6.performer.net.laye
rs.0.1.fn.fn.w1.weight", "stages.6.performer.net.layers.0.1.fn.fn.w1.bias", "stages.6.performer.net.layers.0.1.fn.fn.w2.weight", "stages.6.performer.net.layers.0.1.fn.fn.w2.bias", "stages.6.performer.proj_updater.calls_since_las
t_redraw", "stages.6.performer.proj_updater.instance.layers.0.0.norm.weight", "stages.6.performer.proj_updater.instance.layers.0.0.norm.bias", "stages.6.performer.proj_updater.instance.layers.0.0.fn.fast_attention.projection_mat
rix", "stages.6.performer.proj_updater.instance.layers.0.0.fn.local_attn.rel_pos.inv_freq", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_q.weight", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_q.bias"
, "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_k.weight", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_k.bias", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_v.weight", "stages.6.performe
r.proj_updater.instance.layers.0.0.fn.to_v.bias", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_out.weight", "stages.6.performer.proj_updater.instance.layers.0.0.fn.to_out.bias", "stages.6.performer.proj_updater.ins
tance.layers.0.1.norm.weight", "stages.6.performer.proj_updater.instance.layers.0.1.norm.bias", "stages.6.performer.proj_updater.instance.layers.0.1.fn.fn.w1.weight", "stages.6.performer.proj_updater.instance.layers.0.1.fn.fn.w1
.bias", "stages.6.performer.proj_updater.instance.layers.0.1.fn.fn.w2.weight", "stages.6.performer.proj_updater.instance.layers.0.1.fn.fn.w2.bias", "stages.1.norm1.weight", "stages.1.norm1.bias", "stages.1.norm2.weight", "stages
.1.norm2.bias", "stages.1.conv.norm2d.weight", "stages.1.conv.norm2d.bias", "stages.1.conv.norm2d.running_mean", "stages.1.conv.norm2d.running_var", "stages.1.conv.norm2d.num_batches_tracked", "stages.1.conv.norm1d.weight", "sta
ges.1.conv.norm1d.bias", "stages.1.conv.norm1d.running_mean", "stages.1.conv.norm1d.running_var", "stages.1.conv.norm1d.num_batches_tracked", "stages.1.conv.conv2d.weight", "stages.1.conv.conv2d.bias", "stages.1.conv.conv1d.weig
ht", "stages.1.conv.conv1d.bias", "stages.1.ff.0.weight", "stages.1.ff.0.bias", "stages.1.ff.3.weight", "stages.1.ff.3.bias", "stages.2.norm1.weight", "stages.2.norm1.bias", "stages.2.norm2.weight", "stages.2.norm2.bias", "stage
s.2.conv.norm2d.weight", "stages.2.conv.norm2d.bias", "stages.2.conv.norm2d.running_mean", "stages.2.conv.norm2d.running_var", "stages.2.conv.norm2d.num_batches_tracked", "stages.2.conv.norm1d.weight", "stages.2.conv.norm1d.bias
", "stages.2.conv.norm1d.running_mean", "stages.2.conv.norm1d.running_var", "stages.2.conv.norm1d.num_batches_tracked", "stages.2.conv.conv2d.weight", "stages.2.conv.conv2d.bias", "stages.2.conv.conv1d.weight", "stages.2.conv.conv1d.bias", "stages.2.ff.0.weight", "stages.2.ff.0.bias", "stages.2.ff.3.weight", "stages.2.ff.3.bias".
        size mismatch for stages.0.norm1.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.norm1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.norm2.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.norm2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm2d.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm2d.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm2d.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm2d.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm1d.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm1d.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm1d.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.norm1d.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.conv2d.weight: copying a param with shape torch.Size([192, 12, 3, 3]) from checkpoint, the shape in current model is torch.Size([32, 2, 3, 3]).
        size mismatch for stages.0.conv.conv2d.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.conv.conv1d.weight: copying a param with shape torch.Size([192, 12, 3]) from checkpoint, the shape in current model is torch.Size([32, 2, 3]).
        size mismatch for stages.0.conv.conv1d.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.ff.0.weight: copying a param with shape torch.Size([768, 192]) from checkpoint, the shape in current model is torch.Size([32, 32]).
        size mismatch for stages.0.ff.0.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for stages.0.ff.3.weight: copying a param with shape torch.Size([192, 768]) from checkpoint, the shape in current model is torch.Size([32, 32]).
        size mismatch for stages.0.ff.3.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for linear.weight: copying a param with shape torch.Size([192, 192]) from checkpoint, the shape in current model is torch.Size([32, 192]).
        size mismatch for linear.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).
        size mismatch for fc.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([1, 32]).
(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL> python test_custom.py
모델 로드 중: ./saved_models/888tiny.pkl
✅ 모델 로드 완료
테스트 데이터: 9534개
=== 커스텀 데이터 테스트 시작 ===
테스트 진행:   0%|                                                                                                                                                                                         | 0/596 [00:00<?, ?it/s]
❌ 테스트 실행 중 오류 발생: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 6 is not equal to len(dims) = 5
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 342, in main
    results, overall_metrics, segment_metrics = tester.test_custom_data(
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 64, in test_custom_data
    scores, feat = self.model(features)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\User\Documents\repos\SHIBAL\model.py", line 103, in forward
    x = x.permute(0, 2, 3, 4, 1)
RuntimeError: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 6 is not equal to len(dims) = 5
(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL>

913base 오류 문구
(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL> python test_custom.py
감지된 모델 아키텍처: base
모델 로드 중: ./saved_models/913base.pkl
✅ 모델 로드 완료 (strict=False)
테스트 데이터: 9425개
=== 커스텀 데이터 테스트 시작 ===
테스트 진행:   0%|                                                                                                                                                                                         | 0/590 [00:00<?, ?it/s] 경고: 6차원 텐서 감지, 5차원으로 변환: torch.Size([16, 1, 192, 16, 10, 10])
모델 입력 텐서 형태: torch.Size([16, 192, 16, 10, 10])
테스트 진행:   0%|                                                                                                                                                                                         | 0/590 [00:00<?, ?it/s]
❌ 테스트 실행 중 오류 발생: Given normalized_shape=[192], expected input with shape [*, 192], but got input of size[16, 16, 192, 10, 10]
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 361, in main
    results, overall_metrics, segment_metrics = tester.test_custom_data(
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 83, in test_custom_data
    scores, feat = self.model(features)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\User\Documents\repos\SHIBAL\model.py", line 117, in forward
    x = self.linear(self.norm0(x))
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\normalization.py", line 217, in forward
    return F.layer_norm(
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\functional.py", line 2910, in layer_norm
    return torch.layer_norm(
RuntimeError: Given normalized_shape=[192], expected input with shape [*, 192], but got input of size[16, 16, 192, 10, 10]

(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL> python test_custom.py
감지된 모델 아키텍처: base
모델 로드 중: ./saved_models/913base.pkl
✅ 모델 로드 완료 (strict=False)
테스트 데이터: 9425개
=== 커스텀 데이터 테스트 시작 ===
테스트 진행: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 589/590 [00:17<00:00, 34.45it/s]
❌ 테스트 실행 중 오류 발생: iteration over a 0-d array
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 361, in main
    results, overall_metrics, segment_metrics = tester.test_custom_data(
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 87, in test_custom_data
    results['predictions'].extend(scores.cpu().numpy())
TypeError: iteration over a 0-d array

(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL> python test_custom.py
감지된 모델 아키텍처: tiny
모델 로드 중: ./saved_models/888tiny.pkl
✅ 모델 로드 완료 (strict=False)
테스트 데이터: 9425개
=== 커스텀 데이터 테스트 시작 ===
테스트 진행: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 589/590 [00:49<00:00, 11.91it/s]
❌ 테스트 실행 중 오류 발생: iteration over a 0-d array
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 361, in main
    results, overall_metrics, segment_metrics = tester.test_custom_data(
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 87, in test_custom_data
    results['predictions'].extend(scores.cpu().numpy())
TypeError: iteration over a 0-d array

(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL> python test_custom.py
감지된 모델 아키텍처: base
모델 로드 중: ./saved_models/913base.pkl
✅ 모델 로드 완료 (strict=False)
테스트 데이터: 9425개
=== 커스텀 데이터 테스트 시작 ===
테스트 진행: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 590/590 [00:21<00:00, 27.93it/s]
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(

==================================================
전체 성능
==================================================
ROC AUC: 0.4765
PR AUC: 0.3496
정확도: 0.4308
❌ 테스트 실행 중 오류 발생: '1'
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 361, in main
    results, overall_metrics, segment_metrics = tester.test_custom_data(
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 100, in test_custom_data
    self.print_results(overall_metrics, segment_metrics)
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 187, in print_results
    print(f"정밀도: {overall_metrics['classification_report']['1']['precision']:.4f}")
KeyError: '1'
(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL>


(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL> python test_custom.py
감지된 모델 아키텍처: base
모델 로드 중: ./saved_models/913base.pkl
✅ 모델 로드 완료 (strict=False)
테스트 데이터: 9425개
=== 커스텀 데이터 테스트 시작 ===
테스트 진행: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 590/590 [00:20<00:00, 28.10it/s]
Label distribution: {0.0: 6153, 1.0: 3272}
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(

==================================================
전체 성능
==================================================
ROC AUC: 0.4765
PR AUC: 0.3496
정확도: 0.4308
정밀도(Anomaly): 0.3330
재현율(Anomaly): 0.6375
F1-Score(Anomaly): 0.4375

==================================================
세그먼트별 성능
==================================================

abnormal movement:
  샘플 수: 893
  정상: 0.0, 비정상: 893.0
  ROC AUC: nan
  PR AUC: 1.0000

baggage movement:
  샘플 수: 1019
  정상: 0.0, 비정상: 1019.0
  ROC AUC: nan
  PR AUC: 1.0000

collapse:
  샘플 수: 154
  정상: 0.0, 비정상: 154.0
  ROC AUC: nan
  PR AUC: 1.0000

normal:
  샘플 수: 3803
  정상: 3803.0, 비정상: 0.0
  ROC AUC: nan
  PR AUC: 0.5000

rest:
  샘플 수: 2350
  정상: 2350.0, 비정상: 0.0
  ROC AUC: nan
  PR AUC: 0.5000

suspicious behavior:
  샘플 수: 207
  정상: 0.0, 비정상: 207.0
  ROC AUC: nan
  PR AUC: 1.0000

unknown:
  샘플 수: 442
  정상: 0.0, 비정상: 442.0
  ROC AUC: nan
  PR AUC: 1.0000

violence:
  샘플 수: 557
  정상: 0.0, 비정상: 557.0
  ROC AUC: nan
  PR AUC: 1.0000
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 49464 (\N{HANGUL SYLLABLE SE}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 44536 (\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 47676 (\N{HANGUL SYLLABLE MEON}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 53944 (\N{HANGUL SYLLABLE TEU}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 49368 (\N{HANGUL SYLLABLE SAEM}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 54540 (\N{HANGUL SYLLABLE PEUL}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 49688 (\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 49464 (\N{HANGUL SYLLABLE SE}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 44536 (\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 47676 (\N{HANGUL SYLLABLE MEON}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 53944 (\N{HANGUL SYLLABLE TEU}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 49368 (\N{HANGUL SYLLABLE SAEM}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 54540 (\N{HANGUL SYLLABLE PEUL}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 49688 (\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
UMAP이 설치되지 않아 임베딩 시각화를 건너뜁니다.
❌ 테스트 실행 중 오류 발생: Object of type ndarray is not JSON serializable
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 399, in main
    results, overall_metrics, segment_metrics = tester.test_custom_data(
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 105, in test_custom_data
    self.save_detailed_results(results, overall_metrics, segment_metrics, output_dir)
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 341, in save_detailed_results
    json.dump(output_results, f, indent=2, ensure_ascii=False)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\json\__init__.py", line 179, in dump
    for chunk in iterable:
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\json\encoder.py", line 431, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\json\encoder.py", line 405, in _iterencode_dict
    yield from chunks
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\json\encoder.py", line 405, in _iterencode_dict
    yield from chunks
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\json\encoder.py", line 438, in _iterencode
    o = _default(o)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\json\encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ndarray is not JSON serializable


(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL> python test_custom.py
감지된 모델 아키텍처: base
모델 로드 중: ./saved_models/913base.pkl
✅ 모델 로드 완료 (strict=False)
테스트 데이터: 9425개
=== 커스텀 데이터 테스트 시작 ===
테스트 진행: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 590/590 [00:19<00:00, 30.68it/s]
Label distribution: {0.0: 6153, 1.0: 3272}
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1179: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless
  warnings.warn(
C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\sklearn\metrics\_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.
  warnings.warn(

==================================================
전체 성능
==================================================
ROC AUC: 0.4765
PR AUC: 0.3496
정확도: 0.4308
정밀도(Anomaly): 0.3330
재현율(Anomaly): 0.6375
F1-Score(Anomaly): 0.4375

==================================================
세그먼트별 성능
==================================================

abnormal movement:
  샘플 수: 893
  정상: 0.0, 비정상: 893.0
  ROC AUC: nan
  PR AUC: 1.0000

baggage movement:
  샘플 수: 1019
  정상: 0.0, 비정상: 1019.0
  ROC AUC: nan
  PR AUC: 1.0000

collapse:
  샘플 수: 154
  정상: 0.0, 비정상: 154.0
  ROC AUC: nan
  PR AUC: 1.0000

normal:
  샘플 수: 3803
  정상: 3803.0, 비정상: 0.0
  ROC AUC: nan
  PR AUC: 0.5000

rest:
  샘플 수: 2350
  정상: 2350.0, 비정상: 0.0
  ROC AUC: nan
  PR AUC: 0.5000

suspicious behavior:
  샘플 수: 207
  정상: 0.0, 비정상: 207.0
  ROC AUC: nan
  PR AUC: 1.0000

unknown:
  샘플 수: 442
  정상: 0.0, 비정상: 442.0
  ROC AUC: nan
  PR AUC: 1.0000

violence:
  샘플 수: 557
  정상: 0.0, 비정상: 557.0
  ROC AUC: nan
  PR AUC: 1.0000
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 49464 (\N{HANGUL SYLLABLE SE}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 44536 (\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 47676 (\N{HANGUL SYLLABLE MEON}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 53944 (\N{HANGUL SYLLABLE TEU}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 49368 (\N{HANGUL SYLLABLE SAEM}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 54540 (\N{HANGUL SYLLABLE PEUL}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:291: UserWarning: Glyph 49688 (\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.
  plt.tight_layout()
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 49464 (\N{HANGUL SYLLABLE SE}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 44536 (\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 47676 (\N{HANGUL SYLLABLE MEON}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 53944 (\N{HANGUL SYLLABLE TEU}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 48324 (\N{HANGUL SYLLABLE BYEOL}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 49368 (\N{HANGUL SYLLABLE SAEM}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 54540 (\N{HANGUL SYLLABLE PEUL}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
C:\Users\User\Documents\repos\SHIBAL\test_custom.py:292: UserWarning: Glyph 49688 (\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.
  plt.savefig(f"{output_dir}/custom_test_results.png", dpi=300, bbox_inches='tight')
❌ 테스트 실행 중 오류 발생: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9552,) + inhomogeneous part.
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 421, in main
    results, overall_metrics, segment_metrics = tester.test_custom_data(
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 104, in test_custom_data
    self.visualize_results(results, overall_metrics, segment_metrics, output_dir)
  File "C:\Users\User\Documents\repos\SHIBAL\test_custom.py", line 298, in visualize_results
    feats = np.array(results['features'])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9552,) + inhomogeneous part.
