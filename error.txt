(VAD_p396) PS C:\Users\User\Documents\repos\SHIBAL> python .\train_custom_e2e.py

=== 설정 정보 ===
데이터:
  - 훈련: custom_data/original_images_train.txt
  - 검증: custom_data/original_images_valid.txt
  - 테스트: custom_data/original_images_test.txt
  - 모델: saved_models/888tiny.pkl
훈련:
  - 모델: tiny
  - 배치 크기: 16
  - 학습률: 0.0001
  - 최대 에포크: 50
  - 드롭아웃: 0.4
GPU:
  - 멀티 GPU: True
  - GPU ID: [0, 1]
[GPU] 2개 GPU 사용: [0, 1]
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
  GPU 1: NVIDIA GeForce RTX 4090 (24.0GB)
[E2E] 33298개 이미지 로드됨
[E2E] 정상: 21781개, 비정상: 11517개
[E2E] 4756개 이미지 로드됨
[E2E] 정상: 3111개, 비정상: 1645개
[E2E] 9515개 이미지 로드됨
[E2E] 정상: 6224개, 비정상: 3291개
훈련 데이터: 33298개
검증 데이터: 4756개
테스트 데이터: 9515개
[OK] STEAD 모델 부분 로드: saved_models/888tiny.pkl
[GPU] DataParallel 활성화 (GPU [0, 1] 병렬)

=== End-to-End 훈련 시작 ===
Epoch 0:   0%|                                                                                                                                                                                            | 0/2082 [00:00<?, ?it/s]
전체 진행률:   0%|                                                                                                                                                                                          | 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom_e2e.py", line 630, in <module>
    main()
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom_e2e.py", line 557, in main
    train_loss = train(train_loader, model, optimizer, scheduler, device, epoch, use_multi_gpu)
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom_e2e.py", line 326, in train
    outputs = model(input_data)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\parallel\data_parallel.py", line 194, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\parallel\data_parallel.py", line 213, in parallel_apply
    return parallel_apply(
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\parallel\parallel_apply.py", line 127, in parallel_apply
    output.reraise()
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\_utils.py", line 750, in reraise
    raise exception
ValueError: Caught ValueError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\parallel\parallel_apply.py", line 97, in _worker
    output = module(*input, **kwargs)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom_e2e.py", line 238, in forward
    output = self.stead_model(features)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\User\Documents\repos\SHIBAL\model.py", line 133, in forward
    raise ValueError(f"채널 차원을 감지할 수 없습니다: {x.shape}, init_dim={self.init_dim}")
ValueError: 채널 차원을 감지할 수 없습니다: torch.Size([8, 1, 1, 1, 400]), init_dim=32
