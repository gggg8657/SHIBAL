#!/usr/bin/env python3
"""
8ê°œ ëª¨ë¸ ë™ì‹œ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
uncropped/cropped + tiny/base + finetune/scratch ì¡°í•©ìœ¼ë¡œ ì´ 8ê°œ ëª¨ë¸ì„ ë™ì‹œ í•™ìŠµ
"""

import subprocess
import os
import time
import signal
import sys
from concurrent.futures import ProcessPoolExecutor
import argparse
from pathlib import Path

def train_single_model(config_file, gpu_id=None, additional_args=None, stream=False, log_dir="logs"):
    """ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜"""
    cmd = [sys.executable, "train_custom.py", "--config", config_file]
    
    if gpu_id is not None:
        cmd.extend(["--gpu_ids", str(gpu_id)])
        visible = str(gpu_id)
    else:
        visible = ""
    
    if additional_args:
        cmd.extend(additional_args)
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ì¤€ë¹„
    Path(log_dir).mkdir(parents=True, exist_ok=True)
    cfg_name = os.path.splitext(os.path.basename(config_file))[0]
    log_path = os.path.join(log_dir, f"{cfg_name}.log")
    
    print(f"ğŸš€ ì‹œì‘: {config_file} (GPU: {gpu_id if gpu_id is not None else 'auto'})")
    print(f"ëª…ë ¹ì–´: {' '.join(cmd)}")
    print(f"ğŸ“„ ë¡œê·¸: {log_path}")
    
    # í™˜ê²½ë³€ìˆ˜ ì„¤ì • (GPU ê³ ì •)
    env = os.environ.copy()
    if visible:
        env["CUDA_VISIBLE_DEVICES"] = visible
    
    try:
        if stream:
            # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° + íŒŒì¼ ì €ì¥
            with open(log_path, "w", encoding="utf-8", errors="ignore") as lf:
                proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, env=env)
                for line in proc.stdout:
                    sys.stdout.write(line)
                    lf.write(line)
                proc.wait()
                rc = proc.returncode
        else:
            # ìº¡ì²˜ + íŒŒì¼ ì €ì¥
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600*24, env=env)
            with open(log_path, "w", encoding="utf-8", errors="ignore") as lf:
                lf.write(result.stdout or "")
                lf.write("\n==== STDERR ====\n")
                lf.write(result.stderr or "")
            rc = result.returncode
        
        if rc == 0:
            print(f"âœ… ì™„ë£Œ: {config_file}")
            return True
        else:
            print(f"âŒ ì‹¤íŒ¨: {config_file}")
            print(f"ğŸ” ìì„¸í•œ ë¡œê·¸: {log_path}")
            return False
    except subprocess.TimeoutExpired:
        print(f"â° íƒ€ì„ì•„ì›ƒ: {config_file}")
        return False
    except Exception as e:
        print(f"âŒ ì˜ˆì™¸: {config_file} - {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='8ê°œ ëª¨ë¸ ë™ì‹œ í•™ìŠµ')
    parser.add_argument('--mode', choices=['all', 'finetune', 'scratch', 'uncropped', 'cropped'], 
                       default='all', help='í•™ìŠµ ëª¨ë“œ (ê¸°ë³¸ê°’: all)')
    parser.add_argument('--gpu_assignment', nargs='+', default=None,
                       help='GPU í• ë‹¹ (ì˜ˆ: 0 1 0 1 0 1 0 1)')
    parser.add_argument('--parallel', action='store_true', default=True,
                       help='ë³‘ë ¬ ì‹¤í–‰ (ê¸°ë³¸ê°’: True)')
    parser.add_argument('--max_workers', type=int, default=2,
                       help='ìµœëŒ€ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: 2)')
    parser.add_argument('--stream', action='store_true', default=False,
                       help='ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° (ê¸°ë³¸ê°’: False)')
    parser.add_argument('--log_dir', type=str, default='logs', help='ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    # 8ê°œ ëª¨ë¸ ì„¤ì • íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    all_configs = [
        # íŒŒì¸íŠœë‹ ëª¨ë¸ë“¤
        "config_uncropped_tiny_finetune.json",
        "config_uncropped_base_finetune.json", 
        "config_cropped_tiny_finetune.json",
        "config_cropped_base_finetune.json",
        # From scratch ëª¨ë¸ë“¤
        "config_uncropped_tiny_scratch.json",
        "config_uncropped_base_scratch.json",
        "config_cropped_tiny_scratch.json", 
        "config_cropped_base_scratch.json"
    ]
    
    # ëª¨ë“œë³„ ì„¤ì • íŒŒì¼ ì„ íƒ
    if args.mode == 'finetune':
        configs = all_configs[:4]
        print("ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸ 4ê°œ í•™ìŠµ")
    elif args.mode == 'scratch':
        configs = all_configs[4:]
        print("ğŸ¯ From scratch ëª¨ë¸ 4ê°œ í•™ìŠµ")
    elif args.mode == 'uncropped':
        configs = [all_configs[0], all_configs[1], all_configs[4], all_configs[5]]
        print("ğŸ¯ Uncropped ëª¨ë¸ 4ê°œ í•™ìŠµ")
    elif args.mode == 'cropped':
        configs = [all_configs[2], all_configs[3], all_configs[6], all_configs[7]]
        print("ğŸ¯ Cropped ëª¨ë¸ 4ê°œ í•™ìŠµ")
    else:
        configs = all_configs
        print("ğŸ¯ ëª¨ë“  ëª¨ë¸ 8ê°œ í•™ìŠµ")
    
    print(f"ì„¤ì • íŒŒì¼ë“¤: {configs}")
    print(f"ë³‘ë ¬ ì‹¤í–‰: {args.parallel}")
    print(f"ìµœëŒ€ ì›Œì»¤ ìˆ˜: {args.max_workers}")
    
    # GPU í• ë‹¹ ì„¤ì •
    gpu_assignments = []
    if args.gpu_assignment:
        for gpu_str in args.gpu_assignment:
            gpu_assignments.append(str(gpu_str))
    else:
        # ìë™ í• ë‹¹: GPU 0, 1ë²ˆ ë²ˆê°ˆì•„ê°€ë©° í• ë‹¹
        for i in range(len(configs)):
            gpu_assignments.append("0" if i % 2 == 0 else "1")
    
    print(f"GPU í• ë‹¹: {gpu_assignments}")
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    print("\nğŸ“‹ í•™ìŠµí•  ëª¨ë¸ ëª©ë¡:")
    for i, config in enumerate(configs):
        model_type = "íŒŒì¸íŠœë‹" if "finetune" in config else "From Scratch"
        data_type = "Uncropped" if "uncropped" in config else "Cropped"
        arch_type = "Tiny" if "tiny" in config else "Base"
        gpu_id = gpu_assignments[i] if i < len(gpu_assignments) else "auto"
        print(f"  {i+1}. {data_type} {arch_type} {model_type} (GPU: {gpu_id})")
    
    if args.parallel:
        print("\nğŸ”„ ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘...")
        with ProcessPoolExecutor(max_workers=args.max_workers) as executor:
            futures = []
            for config_file, gpu_id in zip(configs, gpu_assignments):
                futures.append(executor.submit(train_single_model, config_file, gpu_id, None, args.stream, args.log_dir))
            results = [f.result() for f in futures]
    else:
        print("\nğŸ”„ ìˆœì°¨ ì‹¤í–‰ ì‹œì‘...")
        results = []
        for config_file, gpu_id in zip(configs, gpu_assignments):
            ok = train_single_model(config_file, gpu_id, None, args.stream, args.log_dir)
            results.append(ok)
            time.sleep(2)
    
    # ê²°ê³¼ ìš”ì•½
    success_count = sum(results)
    total_count = len(results)
    print(f"\nğŸ“Š í•™ìŠµ ì™„ë£Œ ìš”ì•½:")
    print(f"ì„±ê³µ: {success_count}/{total_count}")
    print(f"ì‹¤íŒ¨: {total_count - success_count}/{total_count}")
    
    print(f"\nâœ… ë¡œê·¸ ë””ë ‰í† ë¦¬: {os.path.abspath(args.log_dir)}")

if __name__ == "__main__":
    main()
