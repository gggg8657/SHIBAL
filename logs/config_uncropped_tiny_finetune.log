[OK] 설정 파일 로드: config_uncropped_tiny_finetune.json

=== 훈련 설정 ===
훈련 데이터: custom_data/custom_train.txt
테스트 데이터: custom_data/custom_test.txt
모델 경로: saved_models/888tiny.pkl
모델 아키텍처: tiny
배치 크기: 16
학습률: 0.0002
최대 에포크: 100
저장 디렉토리: ./ckpt
==============================
[GPU] 사용 가능한 GPU: 1개
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
[GPU] 커맨드라인 GPU 설정: [0]
[GPU] 단일 GPU 모드 (GPU 0번만 사용)
✅ 유효한 데이터: 38144개
📊 데이터 분포: 정상 24963개, 비정상 13181개
✅ 유효한 데이터: 9425개
📊 데이터 분포: 정상 6153개, 비정상 3272개
훈련 데이터: 13181개
테스트 데이터: 9425개
[OK] 프리트레인드 모델 로드: saved_models/888tiny.pkl

=== 훈련 시작 ===

==== STDERR ====

전체 진행률:   0%|          | 0/100 [00:00<?, ?it/s]

Epoch 0: 0it [00:00, ?it/s][AC:\Users\User\Documents\repos\SHIBAL\segment_dataset.py:84: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\utils\tensor_numpy.cpp:209.)
  return torch.from_numpy(arr)


Epoch 0: 1it [00:01,  1.06s/it][A
Epoch 0: 1it [00:01,  1.06s/it]

전체 진행률:   0%|          | 0/100 [00:25<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom.py", line 420, in <module>
    main()
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom.py", line 387, in main
    cost = train(train_loader, model, optimizer, scheduler, device, step, use_multi_gpu)
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom.py", line 150, in train
    for step, (ninput, nlabel, ainput, alabel, ncategory, acategory) in tqdm(enumerate(loader), desc=f"Epoch {epoch}"):
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\tqdm\std.py", line 1181, in __iter__
    for obj in iterable:
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\dataloader.py", line 733, in __next__
    data = self._next_data()
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\dataloader.py", line 1488, in _next_data
    return self._process_data(data, worker_id)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\dataloader.py", line 1550, in _process_data
    data.reraise()
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\_utils.py", line 750, in reraise
    raise exception
AttributeError: Caught AttributeError in DataLoader worker process 1.
Original Traceback (most recent call last):
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\_utils\worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\User\Documents\repos\SHIBAL\segment_dataset.py", line 102, in __getitem__
    if not self.n_ind or not self.a_ind:
AttributeError: 'SegmentDataset' object has no attribute 'n_ind'

