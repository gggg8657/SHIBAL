[OK] ì„¤ì • íŒŒì¼ ë¡œë“œ: config_uncropped_tiny_finetune.json

=== í›ˆë ¨ ì„¤ì • ===
í›ˆë ¨ ë°ì´í„°: custom_data/custom_train.txt
í…ŒìŠ¤íŠ¸ ë°ì´í„°: custom_data/custom_test.txt
ëª¨ë¸ ê²½ë¡œ: saved_models/888tiny.pkl
ëª¨ë¸ ì•„í‚¤í…ì²˜: tiny
ë°°ì¹˜ í¬ê¸°: 16
í•™ìŠµë¥ : 0.0002
ìµœëŒ€ ì—í¬í¬: 100
ì €ì¥ ë””ë ‰í† ë¦¬: ./ckpt
==============================
[GPU] ì‚¬ìš© ê°€ëŠ¥í•œ GPU: 1ê°œ
  GPU 0: NVIDIA GeForce RTX 4090 (24.0GB)
[GPU] ì»¤ë§¨ë“œë¼ì¸ GPU ì„¤ì •: [0]
[GPU] ë‹¨ì¼ GPU ëª¨ë“œ (GPU 0ë²ˆë§Œ ì‚¬ìš©)
âœ… ìœ íš¨í•œ ë°ì´í„°: 38144ê°œ
ğŸ“Š ë°ì´í„° ë¶„í¬: ì •ìƒ 24963ê°œ, ë¹„ì •ìƒ 13181ê°œ
âœ… ìœ íš¨í•œ ë°ì´í„°: 9425ê°œ
ğŸ“Š ë°ì´í„° ë¶„í¬: ì •ìƒ 6153ê°œ, ë¹„ì •ìƒ 3272ê°œ
í›ˆë ¨ ë°ì´í„°: 13181ê°œ
í…ŒìŠ¤íŠ¸ ë°ì´í„°: 9425ê°œ
[OK] í”„ë¦¬íŠ¸ë ˆì¸ë“œ ëª¨ë¸ ë¡œë“œ: saved_models/888tiny.pkl

=== í›ˆë ¨ ì‹œì‘ ===

==== STDERR ====

ì „ì²´ ì§„í–‰ë¥ :   0%|          | 0/100 [00:00<?, ?it/s]

Epoch 0: 0it [00:00, ?it/s][AC:\Users\User\Documents\repos\SHIBAL\segment_dataset.py:84: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\utils\tensor_numpy.cpp:209.)
  return torch.from_numpy(arr)


Epoch 0: 1it [00:01,  1.06s/it][A
Epoch 0: 1it [00:01,  1.06s/it]

ì „ì²´ ì§„í–‰ë¥ :   0%|          | 0/100 [00:25<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom.py", line 420, in <module>
    main()
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom.py", line 387, in main
    cost = train(train_loader, model, optimizer, scheduler, device, step, use_multi_gpu)
  File "C:\Users\User\Documents\repos\SHIBAL\train_custom.py", line 150, in train
    for step, (ninput, nlabel, ainput, alabel, ncategory, acategory) in tqdm(enumerate(loader), desc=f"Epoch {epoch}"):
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\tqdm\std.py", line 1181, in __iter__
    for obj in iterable:
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\dataloader.py", line 733, in __next__
    data = self._next_data()
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\dataloader.py", line 1488, in _next_data
    return self._process_data(data, worker_id)
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\dataloader.py", line 1550, in _process_data
    data.reraise()
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\_utils.py", line 750, in reraise
    raise exception
AttributeError: Caught AttributeError in DataLoader worker process 1.
Original Traceback (most recent call last):
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\_utils\worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\User\anaconda3\envs\VAD_p396\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\User\Documents\repos\SHIBAL\segment_dataset.py", line 102, in __getitem__
    if not self.n_ind or not self.a_ind:
AttributeError: 'SegmentDataset' object has no attribute 'n_ind'

